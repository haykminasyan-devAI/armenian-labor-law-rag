# Armenian Labor Law RAG System - Complete Guide ğŸ“–

## ğŸ¯ What This System Does

Ask questions about Armenian Labor Law in Armenian â†’ Get accurate answers with article citations

**Example:**
- **Question**: "Ô»Õ¶Õ¹ÕºÕ«Õ½Õ«ÕÕ¶ Õ§ Õ¡Õ·Õ­Õ¡Õ¿Õ¡Õ¶Ö„Õ¡ÕµÕ«Õ¶ ÕªÕ¡Õ´Õ¥Ö€Õ« Õ½Õ¡Õ°Õ´Õ¡Õ¶Õ¡ÖƒÕ¡Õ¯Õ¸Ö‚Õ´Õ¨:"
- **Answer**: Detailed response with citations to specific Labor Code articles (e.g., "Õ€Õ¡Õ´Õ¡Õ±Õ¡ÕµÕ¶ Õ€Õ¸Õ¤Õ¾Õ¡Õ® 145-Õ«...")

---

## ğŸš€ Quick Start (3 Steps)

### Step 1: Setup (First Time Only)

```bash
cd /home/hayk.minasyan/Project/NLP_proj
source venv/bin/activate
```

**API Key** (already configured):
```
NVIDIA API: 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
```

### Step 2: Run the Interface

```bash
streamlit run interface/streamlit_app_modern.py --server.port 8501
```

Access at: **http://localhost:8501**

### Step 3: Use the System

1. Select **Model**: Qwen 3 Next 80B (recommended)
2. Select **Retrieval**: Hybrid (recommended)
3. Ask questions in Armenian
4. Get answers with citations!

---

## ğŸ“ Important Files (What You Need to Know)

### **Core System Files** (Don't Delete!)

```
âœ… MUST KEEP - Production System:

interface/
â””â”€â”€ streamlit_app_modern.py          # Main web interface

src/
â”œâ”€â”€ generation/
â”‚   â”œâ”€â”€ generator.py                 # LLM wrapper
â”‚   â”œâ”€â”€ prompt_templates.py          # Armenian prompts â­
â”‚   â””â”€â”€ rag_pipeline.py              # Main pipeline
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ hybrid_retriever.py          # Hybrid retrieval (best) â­
â”‚   â”œâ”€â”€ bm25_retriever.py            # Keyword search
â”‚   â””â”€â”€ dense_retriever.py           # Semantic search
â””â”€â”€ evaluation/
    â””â”€â”€ metrics.py                   # All metrics

data/
â”œâ”€â”€ chunks/
â”‚   â””â”€â”€ labor_law_chunks_hybrid.json  # Optimized chunks â­
â””â”€â”€ indices/hybrid_v2/                # Production indices â­
    â”œâ”€â”€ bm25.pkl
    â”œâ”€â”€ faiss.index
    â””â”€â”€ hybrid_config.json

scripts/
â”œâ”€â”€ eval_qwen3_80b_hybrid_final.py   # Best model evaluation â­
â”œâ”€â”€ eval_bm25_deepseek_complete.py   # DeepSeek evaluation
â”œâ”€â”€ create_hybrid_chunks.py          # Create chunks
â”œâ”€â”€ build_hybrid_chunks_index.py     # Build indices
â””â”€â”€ test_sentence_completion_qwen.py # Test completeness

OrinAi_1 (1).txt                     # Test dataset (85 questions) â­
requirements.txt                     # Dependencies
```

### **Configuration Files**

```
configs/
â”œâ”€â”€ bm25_config.yaml        # BM25 settings
â”œâ”€â”€ dense_config.yaml       # Dense retrieval settings
â”œâ”€â”€ hybrid_config.yaml      # Hybrid settings (best)
â””â”€â”€ llm_config.yaml         # Model settings
```

### **Documentation Files**

```
README.md                           # Overview & installation
COMPLETE_GUIDE.md                   # This file â­
HOW_TO_RUN_RAG.md                   # Detailed usage
HYBRID_RETRIEVAL.md                 # Retrieval explanation
EVALUATION_METRICS_EXPLAINED.md     # Metrics details
CHATBOT_USAGE.md                    # Interface guide
DEEPSEEK_USAGE.md                   # DeepSeek model guide
docs/HYBRID_CHUNKING_SUMMARY.md     # Chunking strategy
```

---

## ğŸ® How to Use

### **Option 1: Web Interface (Easiest)**

```bash
# Start the app
streamlit run interface/streamlit_app_modern.py

# Use in browser at http://localhost:8501
```

**Settings in Interface:**
- **Generation Model**: Qwen 3 Next 80B (best) or DeepSeek
- **Retrieval Method**: Hybrid (best), BM25, or Dense
- **Max Tokens**: 6000 (current setting)

### **Option 2: Python Code**

```python
from src.retrieval.hybrid_retriever import HybridRetriever
from src.generation.rag_pipeline import RAGPipeline
from src.generation.generator import LLMGenerator
import json

# 1. Load chunks
with open('data/chunks/labor_law_chunks_hybrid.json', 'r') as f:
    chunks = json.load(f)

# 2. Setup retriever
retriever = HybridRetriever(chunks, bm25_weight=0.5, dense_weight=0.5)
retriever.load_index('data/indices/hybrid_v2')

# 3. Setup generator
generator = LLMGenerator(
    model_name="qwen/qwen3-next-80b-a3b-instruct",
    provider="nvidia",
    api_key="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",
    max_tokens=6000,
    temperature=0.1
)

# 4. Create pipeline
pipeline = RAGPipeline(retriever=retriever, generator=generator)

# 5. Ask question
result = pipeline.answer_question(
    "Ô»Õ¶Õ¹ÕºÕ«Õ½Õ«ÕÕ¶ Õ§ Õ¡Õ·Õ­Õ¡Õ¿Õ¡Õ¶Ö„Õ¡ÕµÕ«Õ¶ ÕªÕ¡Õ´Õ¥Ö€Õ« Õ½Õ¡Õ°Õ´Õ¡Õ¶Õ¡ÖƒÕ¡Õ¯Õ¸Ö‚Õ´Õ¨:",
    top_k=5
)

print("Answer:", result['answer'])
print("Articles:", result['cited_articles'])
```

---

## ğŸ“Š Run Evaluation

### Evaluate Current Best System

```bash
# Qwen 3 Next 80B + Hybrid Retrieval
python scripts/eval_qwen3_80b_hybrid_final.py
```

**What it tests:**
- 85 questions from `OrinAi_1 (1).txt`
- Retrieval quality (MRR, Recall, Precision)
- Answer quality (Citations, Hallucinations, Similarity)
- Sentence completion (Armenian "Ö‰")

**Results saved to:**
```
results/evaluation/qwen3_80b_hybrid_chunks_*.json
results/evaluation/qwen3_80b_hybrid_chunks_summary_*.txt
```

### Best Results So Far

```
ğŸ‰ Qwen 3 Next 80B + Hybrid Retrieval:

ğŸ“Š RETRIEVAL:
âœ… MRR: 0.583 (first relevant at rank ~1.7)
âœ… Recall@3: 0.565 (found 56.5% of relevant articles)
âœ… Hit@3: 0.647 (64.7% got â‰¥1 relevant article)

ğŸ“ ANSWER QUALITY:
â­ Citation Accuracy: 1.000 (100% perfect!)
â­ Hallucination Rate: 0.00 (ZERO hallucinations!)
â­ Semantic Similarity: 0.830 (Very good!)
```

---

## ğŸ”§ System Architecture

```
User Question (Armenian)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit Interface (8501)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG Pipeline                   â”‚
â”‚  (src/generation/rag_pipeline)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hybrid Retriever               â”‚ â† Best Method!
â”‚  (BM25 + Dense + RRF Fusion)    â”‚
â”‚                                 â”‚
â”‚  â€¢ BM25: Keyword matching       â”‚
â”‚  â€¢ Dense: Semantic similarity   â”‚
â”‚  â€¢ RRF: Combine both (0.5/0.5)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Top-5 Relevant Chunks          â”‚
â”‚  (avg 444 tokens each)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Generation                 â”‚
â”‚                                 â”‚
â”‚  Model: Qwen 3 Next 80B         â”‚
â”‚  max_tokens: 6000               â”‚
â”‚  temperature: 0.1               â”‚
â”‚  Prompt: Armenian QA template   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Answer + Citations             â”‚
â”‚  (Complete Armenian sentences)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Key Improvements Made

### Problem 1: Incomplete Sentences âŒ â†’ âœ…
**Issue**: Answers cut off mid-sentence  
**Solution**:
- âœ… Increased `max_tokens` from 2000 â†’ 6000
- âœ… Optimized prompt for completeness
- âœ… Reduced chunk sizes (2117 â†’ 444 tokens avg)

### Problem 2: Large Chunks âŒ â†’ âœ…
**Issue**: Chunks too big (avg 2117 tokens, max 11,328!)  
**Solution**:
- âœ… Hybrid chunking: Split long articles while preserving context
- âœ… Target: 600 tokens per chunk
- âœ… Result: 444 tokens average, manageable sizes

### Problem 3: Poor Retrieval âŒ â†’ âœ…
**Issue**: Missing relevant articles  
**Solution**:
- âœ… Hybrid retrieval (RRF fusion of BM25 + Dense)
- âœ… Armenian embeddings (Metric-AI/armenian-text-embeddings-1)
- âœ… Balanced weights (0.5/0.5)

---

## ğŸ“š Important Settings

### Current Production Settings

**Model Configuration** (in `interface/streamlit_app_modern.py`):
```python
# Qwen 3 Next 80B (Best Model)
model_name = "qwen/qwen3-next-80b-a3b-instruct"
max_tokens = 6000        # â­ For complete sentences
temperature = 0.1        # â­ For consistent outputs
api_key = "nvapi-GSdP..."
```

**Retrieval Configuration**:
```python
# Hybrid Retrieval (Best Method)
bm25_weight = 0.5        # â­ Keyword search weight
dense_weight = 0.5       # â­ Semantic search weight
top_k = 5                # â­ Return top 5 chunks
```

**Chunking Configuration**:
```python
# Hybrid Chunks (Optimized)
target_chunk_size = 600 tokens
actual_avg_size = 444 tokens
max_size = ~1200 tokens
method = "article-based with sub-sections"
```

---

## ğŸ¯ What Each File Does

### **Interface**
- `interface/streamlit_app_modern.py`: Web UI - START HERE! ğŸŒŸ

### **Core System**
- `src/generation/rag_pipeline.py`: Main RAG logic
- `src/generation/generator.py`: Talks to LLM APIs
- `src/generation/prompt_templates.py`: Armenian prompts
- `src/retrieval/hybrid_retriever.py`: Best retrieval method
- `src/evaluation/metrics.py`: All evaluation metrics

### **Scripts**
- `scripts/eval_qwen3_80b_hybrid_final.py`: Run full evaluation
- `scripts/create_hybrid_chunks.py`: Create optimized chunks (if needed)
- `scripts/build_hybrid_chunks_index.py`: Build indices (if needed)
- `scripts/test_sentence_completion_qwen.py`: Test sentence endings

### **Data**
- `data/chunks/labor_law_chunks_hybrid.json`: Optimized chunks (444 tokens avg)
- `data/indices/hybrid_v2/`: Production indices (BM25 + FAISS)
- `OrinAi_1 (1).txt`: Test questions (85 Q&A pairs)

---

## âš™ï¸ Troubleshooting

### Issue: "ModuleNotFoundError"
```bash
source venv/bin/activate
pip install -r requirements.txt
```

### Issue: "NVIDIA API Error"
- Check internet connection
- API key is in the code (already set)
- Try again in a few seconds

### Issue: "Slow responses"
- Normal! API calls take 5-15 seconds
- Qwen 80B is a huge model (better quality = slower)

### Issue: "Incomplete sentences"
- Current setting: `max_tokens=6000` (should be good)
- Check results/evaluation/ for completion rates
- Can increase to 8000 if needed

### Issue: "Port 8501 already in use"
```bash
# Kill existing Streamlit
pkill -f streamlit

# Or use different port
streamlit run interface/streamlit_app_modern.py --server.port 8502
```

---

## ğŸ“ Understanding the System

### What is RAG?
**Retrieval-Augmented Generation** = Find relevant info + Generate answer

1. **Retrieval**: Search for relevant articles (BM25 + Dense)
2. **Augmentation**: Add context to the prompt
3. **Generation**: LLM creates answer based on context

### Why Hybrid Retrieval?
- **BM25**: Good at keyword matching ("Õ¡Õ·Õ­Õ¡Õ¿Õ¡Õ¶Ö„Õ¡ÕµÕ«Õ¶ ÕªÕ¡Õ´")
- **Dense**: Good at semantic meaning ("working hours")
- **Hybrid**: Combines both strengths! ğŸ¯

### Why Hybrid Chunks?
- Too big â†’ Wastes tokens, hits limits âŒ
- Too small â†’ Loses context âŒ
- Hybrid â†’ Perfect balance! âœ…
  - Keeps article context
  - Splits long articles
  - Average 444 tokens

### Why Qwen 3 Next 80B?
- **80 billion parameters** = Very smart
- **Multilingual** = Great with Armenian
- **Latest model** = State-of-the-art
- **NVIDIA API** = Fast access

---

## ğŸ“ˆ Performance Metrics Explained

### Retrieval Metrics

**MRR (Mean Reciprocal Rank)**: 0.583
- Higher = better (max 1.0)
- 0.583 means first relevant article is typically at rank 1-2

**Recall@3**: 0.565
- Found 56.5% of all relevant articles in top-3
- Higher = more complete coverage

**Hit@3**: 0.647
- 64.7% of questions got at least one relevant article
- Shows retrieval is working!

### Answer Quality Metrics

**Citation Accuracy**: 1.000 (Perfect! â­)
- All answers cite correct articles
- No incorrect references

**Hallucination Rate**: 0.00 (Perfect! â­â­â­)
- Zero made-up information
- All answers grounded in context

**Semantic Similarity**: 0.830 (Very Good!)
- Answers capture the meaning well
- Close to reference answers

---

## ğŸš¦ System Status

âœ… **PRODUCTION READY**

- âœ… Optimized chunks (444 tokens avg)
- âœ… Hybrid retrieval (BM25 + Dense)
- âœ… Best model (Qwen 3 Next 80B)
- âœ… Complete sentences (max_tokens=6000)
- âœ… Zero hallucinations
- âœ… Perfect citations
- âœ… Modern web interface
- âœ… Comprehensive evaluation

---

## ğŸ“ Quick Commands Reference

```bash
# Activate environment
source venv/bin/activate

# Run web interface
streamlit run interface/streamlit_app_modern.py

# Run evaluation
python scripts/eval_qwen3_80b_hybrid_final.py

# Test sentence completion
python scripts/test_sentence_completion_qwen.py

# Check results
cat results/evaluation/qwen3_80b_hybrid_chunks_summary_*.txt

# Stop Streamlit
pkill -f streamlit
```

---

## ğŸ‰ Summary

**This is a complete, production-ready RAG system for Armenian Labor Law.**

**To use it:**
1. `source venv/bin/activate`
2. `streamlit run interface/streamlit_app_modern.py`
3. Go to http://localhost:8501
4. Ask questions in Armenian!

**Best Configuration:**
- Model: Qwen 3 Next 80B
- Retrieval: Hybrid (BM25 + Dense)
- Chunks: Hybrid (444 tokens avg)
- Max Tokens: 6000

**Results:**
- â­ 100% citation accuracy
- â­ 0% hallucination rate
- â­ 83% semantic similarity
- â­ Complete Armenian sentences (Ö‰)

---

**Version**: 1.0.0 (Production)  
**Last Updated**: January 21, 2026  
**Status**: âœ… Ready to Use!
